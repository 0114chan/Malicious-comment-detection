import pandas as pd
import torch
from torchtext.data import Field, TabularDataset, BucketIterator
import torch.nn as nn
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
import torch.optim as optim
import random

import warnings
warnings.filterwarnings('ignore')
torch.cuda.is_available()

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

TEXT = data.Field(tokenize = 'spacy',
                  tokenizer_language = 'en_core_web_sm')
LABEL = data.LabelField(dtype = torch.float)

fields = {'comment': ('comment',TEXT), 'toxicity': ('toxicity',LABEL)}

train_data = data.TabularDataset.splits(
                            path = './',
                            train = 'train.csv',
                            format = 'csv',
                            fields = fields,  
)[0]
vars(train_data[0])

train_data, valid_data = train_data.split(random_state=random.seed(42))
valid_data, test_data = valid_data.split(random_state=random.seed(42))

print(len(train_data))
print(len(valid_data))
print(len(test_data))

TEXT.build_vocab(train_data)
len(TEXT.vocab)
TEXT.build_vocab(train_data, min_freq=2)
len(TEXT.vocab)

MAX_VOCAB_SIZE = 60000

TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)
LABEL.build_vocab(train_data)
TEXT.vocab.freqs.most_common(20)
TEXT.vocab.itos[:10]

BATCH_SIZE = 64

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(
    (train_data, valid_data, test_data), 
    batch_size = BATCH_SIZE,
    device = device,
    sort_key = lambda x: len(x.comment),
    sort_within_batch = False,
)
next(iter(train_iterator)).comment.shape
